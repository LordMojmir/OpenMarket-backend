[
    {
        "_id": "621ffdd236468d709f181d5e",
        "id": "allenai/ai2_arc",
        "author": "allenai",
        "disabled": false,
        "gated": false,
        "lastModified": "2023-12-21T15:09:48.000Z",
        "likes": 100,
        "private": false,
        "sha": "210d026faf9955653af8916fad021475a3f00453",
        "description": "\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for \"ai2_arc\"\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nA new dataset of 7,787 genuine grade-school level, multiple-choice science questions, assembled to encourage research in\n advanced question-answering. The dataset is partitioned into a Challenge Set and an Easy Set, where the former contains\n only questions answered incorrectly by both a retrieval-based algorithm and a word co-occurrence algorithm. We are also\n including a corpus of over 14 million science sentences\u2026 See the full description on the dataset page: https://huggingface.co/datasets/allenai/ai2_arc.",
        "downloads": 548821,
        "tags": [
            "task_categories:question-answering",
            "task_ids:open-domain-qa",
            "task_ids:multiple-choice-qa",
            "annotations_creators:found",
            "language_creators:found",
            "multilinguality:monolingual",
            "source_datasets:original",
            "language:en",
            "license:cc-by-sa-4.0",
            "size_categories:1K<n<10K",
            "format:parquet",
            "modality:text",
            "library:datasets",
            "library:pandas",
            "library:mlcroissant",
            "arxiv:1803.05457",
            "region:us",
            "croissant"
        ],
        "createdAt": "2022-03-02T23:29:22.000Z",
        "key": ""
    },
    {
        "_id": "621ffdd236468d709f181e5e",
        "id": "cais/mmlu",
        "author": "cais",
        "disabled": false,
        "gated": false,
        "lastModified": "2024-03-08T20:36:26.000Z",
        "likes": 270,
        "private": false,
        "sha": "c30699e8356da336a370243923dbaf21066bb9fe",
        "description": "\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for MMLU\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nMeasuring Massive Multitask Language Understanding by Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt (ICLR 2021).\nThis is a massive multitask test consisting of multiple-choice questions from various branches of knowledge. The test spans subjects in the humanities, social sciences, hard sciences, and other areas that are important for some people to learn. This covers 57\u2026 See the full description on the dataset page: https://huggingface.co/datasets/cais/mmlu.",
        "downloads": 522630,
        "paperswithcode_id": "mmlu",
        "tags": [
            "task_categories:question-answering",
            "task_ids:multiple-choice-qa",
            "annotations_creators:no-annotation",
            "language_creators:expert-generated",
            "multilinguality:monolingual",
            "source_datasets:original",
            "language:en",
            "license:mit",
            "size_categories:100K<n<1M",
            "format:parquet",
            "modality:text",
            "library:datasets",
            "library:pandas",
            "library:mlcroissant",
            "arxiv:2009.03300",
            "arxiv:2005.00700",
            "arxiv:2005.14165",
            "arxiv:2008.02275",
            "region:us",
            "croissant"
        ],
        "createdAt": "2022-03-02T23:29:22.000Z",
        "key": ""
    },
    {
        "_id": "621ffdd236468d709f181e3f",
        "id": "nyu-mll/glue",
        "author": "nyu-mll",
        "disabled": false,
        "gated": false,
        "lastModified": "2024-01-30T07:41:18.000Z",
        "likes": 336,
        "private": false,
        "sha": "bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c",
        "description": "\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for GLUE\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nGLUE, the General Language Understanding Evaluation benchmark (https://gluebenchmark.com/) is a collection of resources for training, evaluating, and analyzing natural language understanding systems.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nThe leaderboard for the GLUE benchmark can be found at this address. It comprises the following tasks:\n\n\t\n\t\t\n\t\n\t\n\t\tax\n\t\n\nA manually-curated evaluation dataset for fine-grained\u2026 See the full description on the dataset page: https://huggingface.co/datasets/nyu-mll/glue.",
        "downloads": 114675,
        "paperswithcode_id": "glue",
        "tags": [
            "task_categories:text-classification",
            "task_ids:acceptability-classification",
            "task_ids:natural-language-inference",
            "task_ids:semantic-similarity-scoring",
            "task_ids:sentiment-classification",
            "task_ids:text-scoring",
            "annotations_creators:other",
            "language_creators:other",
            "multilinguality:monolingual",
            "source_datasets:original",
            "language:en",
            "license:other",
            "size_categories:1M<n<10M",
            "format:parquet",
            "modality:tabular",
            "modality:text",
            "library:datasets",
            "library:pandas",
            "library:mlcroissant",
            "arxiv:1804.07461",
            "region:us",
            "qa-nli",
            "coreference-nli",
            "paraphrase-identification",
            "croissant"
        ],
        "createdAt": "2022-03-02T23:29:22.000Z",
        "key": ""
    },
    {
        "_id": "621ffdd236468d709f181dd1",
        "id": "hendrycks/competition_math",
        "author": "hendrycks",
        "disabled": false,
        "gated": false,
        "lastModified": "2023-06-08T06:40:09.000Z",
        "likes": 94,
        "private": false,
        "sha": "71b758ecc688b2822d07ffa7f8393299f1dc7cac",
        "citation": "@article{hendrycksmath2021,\n  title={Measuring Mathematical Problem Solving With the MATH Dataset},\n  author={Dan Hendrycks\n    and Collin Burns\n    and Saurav Kadavath\n    and Akul Arora\n    and Steven Basart\n    and Eric Tang\n    and Dawn Song\n    and Jacob Steinhardt},\n  journal={arXiv preprint arXiv:2103.03874},\n  year={2021}\n}",
        "description": "The Mathematics Aptitude Test of Heuristics (MATH) dataset consists of problems\nfrom mathematics competitions, including the AMC 10, AMC 12, AIME, and more.\nEach problem in MATH has a full step-by-step solution, which can be used to teach\nmodels to generate answer derivations and explanations.",
        "downloads": 83373,
        "tags": [
            "task_categories:text2text-generation",
            "annotations_creators:expert-generated",
            "language_creators:expert-generated",
            "multilinguality:monolingual",
            "source_datasets:original",
            "language:en",
            "license:mit",
            "size_categories:10K<n<100K",
            "arxiv:2103.03874",
            "region:us",
            "explanation-generation"
        ],
        "createdAt": "2022-03-02T23:29:22.000Z",
        "key": ""
    },
    {
        "_id": "621ffdd236468d709f181dd0",
        "id": "tau/commonsense_qa",
        "author": "tau",
        "disabled": false,
        "gated": false,
        "lastModified": "2024-01-04T07:44:16.000Z",
        "likes": 58,
        "private": false,
        "sha": "94630fe30dad47192a8546eb75f094926d47e155",
        "description": "\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for \"commonsense_qa\"\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nCommonsenseQA is a new multiple-choice question answering dataset that requires different types of commonsense knowledge\nto predict the correct answers . It contains 12,102 questions with one correct answer and four distractor answers.\nThe dataset is provided in two major training/validation/testing set splits: \"Random split\" which is the main evaluation\nsplit, and \"Question token split\", see paper for details.\u2026 See the full description on the dataset page: https://huggingface.co/datasets/tau/commonsense_qa.",
        "downloads": 45330,
        "paperswithcode_id": "commonsenseqa",
        "tags": [
            "task_categories:question-answering",
            "task_ids:open-domain-qa",
            "annotations_creators:crowdsourced",
            "language_creators:crowdsourced",
            "multilinguality:monolingual",
            "source_datasets:original",
            "language:en",
            "license:mit",
            "size_categories:10K<n<100K",
            "format:parquet",
            "modality:text",
            "library:datasets",
            "library:pandas",
            "library:mlcroissant",
            "arxiv:1811.00937",
            "region:us",
            "croissant"
        ],
        "createdAt": "2022-03-02T23:29:22.000Z",
        "key": ""
    },
    {
        "_id": "621ffdd236468d709f181e16",
        "id": "dair-ai/emotion",
        "author": "dair-ai",
        "disabled": false,
        "gated": false,
        "lastModified": "2023-04-20T08:08:15.000Z",
        "likes": 257,
        "private": false,
        "sha": "9ce63038044ae35ec1305d998d1882fcecd70ec8",
        "citation": "@inproceedings{saravia-etal-2018-carer,\n    title = \"{CARER}: Contextualized Affect Representations for Emotion Recognition\",\n    author = \"Saravia, Elvis  and\n      Liu, Hsien-Chi Toby  and\n      Huang, Yen-Hao  and\n      Wu, Junlin  and\n      Chen, Yi-Shin\",\n    booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\",\n    month = oct # \"-\" # nov,\n    year = \"2018\",\n    address = \"Brussels, Belgium\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/D18-1404\",\n    doi = \"10.18653/v1/D18-1404\",\n    pages = \"3687--3697\",\n    abstract = \"Emotions are expressed in nuanced ways, which varies by collective or individual experiences, knowledge, and beliefs. Therefore, to understand emotion, as conveyed through text, a robust mechanism capable of capturing and modeling different linguistic nuances and phenomena is needed. We propose a semi-supervised, graph-based algorithm to produce rich structural descriptors which serve as the building blocks for constructing contextualized affect representations from text. The pattern-based representations are further enriched with word embeddings and evaluated through several emotion recognition tasks. Our experimental results demonstrate that the proposed method outperforms state-of-the-art techniques on emotion recognition tasks.\",\n}",
        "description": "Emotion is a dataset of English Twitter messages with six basic emotions: anger, fear, joy, love, sadness, and surprise. For more detailed information please refer to the paper.",
        "downloads": 24693,
        "paperswithcode_id": "emotion",
        "tags": [
            "task_categories:text-classification",
            "task_ids:multi-class-classification",
            "annotations_creators:machine-generated",
            "language_creators:machine-generated",
            "multilinguality:monolingual",
            "source_datasets:original",
            "language:en",
            "license:other",
            "size_categories:100K<n<1M",
            "modality:text",
            "library:datasets",
            "library:mlcroissant",
            "region:us",
            "emotion-classification",
            "croissant"
        ],
        "createdAt": "2022-03-02T23:29:22.000Z",
        "key": ""
    },
    {
        "_id": "621ffdd236468d709f181f09",
        "id": "Skylion007/openwebtext",
        "author": "Skylion007",
        "disabled": false,
        "gated": false,
        "lastModified": "2024-05-17T17:56:27.000Z",
        "likes": 322,
        "private": false,
        "sha": "f3808c30e817981b845ec549c43e82bb467d8144",
        "citation": "@misc{Gokaslan2019OpenWeb,\n  title={OpenWebText Corpus},\n  author={Aaron Gokaslan*, Vanya Cohen*, Ellie Pavlick, Stefanie Tellex},\n  howpublished{\\\\url{http://Skylion007.github.io/OpenWebTextCorpus}},\n  year={2019}\n}",
        "description": "An open-source replication of the WebText dataset from OpenAI.",
        "downloads": 19473,
        "paperswithcode_id": "openwebtext",
        "tags": [
            "task_categories:text-generation",
            "task_categories:fill-mask",
            "task_ids:language-modeling",
            "task_ids:masked-language-modeling",
            "annotations_creators:no-annotation",
            "language_creators:found",
            "multilinguality:monolingual",
            "source_datasets:original",
            "language:en",
            "license:cc0-1.0",
            "size_categories:1M<n<10M",
            "region:us"
        ],
        "createdAt": "2022-03-02T23:29:22.000Z",
        "key": ""
    },
    {
        "_id": "621ffdd236468d709f181e77",
        "id": "stanfordnlp/imdb",
        "author": "stanfordnlp",
        "disabled": false,
        "gated": false,
        "lastModified": "2024-01-04T12:09:45.000Z",
        "likes": 208,
        "private": false,
        "sha": "e6281661ce1c48d982bc483cf8a173c1bbeb5d31",
        "description": "\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for \"imdb\"\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nLarge Movie Review Dataset.\nThis is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\n\t\n\t\tLanguages\n\t\n\nMore Information Needed\u2026 See the full description on the dataset page: https://huggingface.co/datasets/stanfordnlp/imdb.",
        "downloads": 19193,
        "paperswithcode_id": "imdb-movie-reviews",
        "tags": [
            "task_categories:text-classification",
            "task_ids:sentiment-classification",
            "annotations_creators:expert-generated",
            "language_creators:expert-generated",
            "multilinguality:monolingual",
            "source_datasets:original",
            "language:en",
            "license:other",
            "size_categories:100K<n<1M",
            "format:parquet",
            "modality:text",
            "library:datasets",
            "library:pandas",
            "library:mlcroissant",
            "region:us",
            "croissant"
        ],
        "createdAt": "2022-03-02T23:29:22.000Z",
        "key": ""
    },
    {
        "_id": "621ffdd236468d709f181f9c",
        "id": "rajpurkar/squad_v2",
        "author": "rajpurkar",
        "disabled": false,
        "gated": false,
        "lastModified": "2024-03-04T13:55:27.000Z",
        "likes": 154,
        "private": false,
        "sha": "3ffb306f725f7d2ce8394bc1873b24868140c412",
        "description": "\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for SQuAD 2.0\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nStanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.\nSQuAD 2.0 combines the 100,000 questions in SQuAD1.1 with over 50,000 unanswerable questions written adversarially by\u2026 See the full description on the dataset page: https://huggingface.co/datasets/rajpurkar/squad_v2.",
        "downloads": 18984,
        "paperswithcode_id": "squad",
        "tags": [
            "task_categories:question-answering",
            "task_ids:open-domain-qa",
            "task_ids:extractive-qa",
            "annotations_creators:crowdsourced",
            "language_creators:crowdsourced",
            "multilinguality:monolingual",
            "source_datasets:original",
            "language:en",
            "license:cc-by-sa-4.0",
            "size_categories:100K<n<1M",
            "format:parquet",
            "modality:text",
            "library:datasets",
            "library:pandas",
            "library:mlcroissant",
            "arxiv:1806.03822",
            "arxiv:1606.05250",
            "region:us",
            "croissant"
        ],
        "createdAt": "2022-03-02T23:29:22.000Z",
        "key": ""
    },
    {
        "_id": "621ffdd236468d709f181e5d",
        "id": "Rowan/hellaswag",
        "author": "Rowan",
        "disabled": false,
        "gated": false,
        "lastModified": "2023-09-28T14:49:00.000Z",
        "likes": 76,
        "private": false,
        "sha": "6002345709e0801764318f06bf06ce1e7d1a1fe3",
        "citation": "@inproceedings{zellers2019hellaswag,\n    title={HellaSwag: Can a Machine Really Finish Your Sentence?},\n    author={Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},\n    booktitle ={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},\n    year={2019}\n}",
        "description": "HellaSwag: Can a Machine Really Finish Your Sentence? is a new dataset for commonsense NLI. A paper was published at ACL2019.",
        "downloads": 17379,
        "paperswithcode_id": "hellaswag",
        "tags": [
            "language:en",
            "size_categories:10K<n<100K",
            "modality:text",
            "library:datasets",
            "library:mlcroissant",
            "arxiv:1905.07830",
            "region:us",
            "croissant"
        ],
        "createdAt": "2022-03-02T23:29:22.000Z",
        "key": ""
    },
    {
        "_id": "621ffdd236468d709f1823d1",
        "id": "Helsinki-NLP/tatoeba_mt",
        "author": "Helsinki-NLP",
        "disabled": false,
        "gated": false,
        "lastModified": "2022-10-21T15:50:25.000Z",
        "likes": 52,
        "private": false,
        "sha": "9635372e5421ccacda7db58e88741617867a9204",
        "citation": "@inproceedings{tiedemann-2020-tatoeba,\n    title = \"The {T}atoeba {T}ranslation {C}hallenge {--} {R}ealistic Data Sets for Low Resource and Multilingual {MT}\",\n    author = {Tiedemann, J{\\\"o}rg},\n    booktitle = \"Proceedings of the Fifth Conference on Machine Translation\",\n    month = nov,\n    year = \"2020\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2020.wmt-1.139\",\n    pages = \"1174--1182\",\n}",
        "description": "The Tatoeba Translation Challenge is a multilingual data set of\nmachine translation benchmarks derived from user-contributed\ntranslations collected by [Tatoeba.org](https://tatoeba.org/) and\nprovided as parallel corpus from [OPUS](https://opus.nlpl.eu/). This\ndataset includes test and development data sorted by language pair. It\nincludes test sets for hundreds of language pairs and is continuously\nupdated. Please, check the version number tag to refer to the release\nthat your are using.",
        "downloads": 16279,
        "tags": [
            "annotations_creators:no-annotation",
            "language_creators:crowdsourced",
            "multilinguality:translation",
            "source_datasets:original",
            "language:af",
            "language:ar",
            "language:az",
            "language:be",
            "language:bg",
            "language:bn",
            "language:br",
            "language:bs",
            "language:ca",
            "language:ch",
            "language:cs",
            "language:cv",
            "language:cy",
            "language:da",
            "language:de",
            "language:el",
            "language:en",
            "language:eo",
            "language:es",
            "language:et",
            "language:eu",
            "language:fa",
            "language:fi",
            "language:fo",
            "language:fr",
            "language:fy",
            "language:ga",
            "language:gd",
            "language:gl",
            "language:gn",
            "language:he",
            "language:hi",
            "language:hr",
            "language:hu",
            "language:hy",
            "language:ia",
            "language:id",
            "language:ie",
            "language:io",
            "language:is",
            "language:it",
            "language:ja",
            "language:jv",
            "language:ka",
            "language:kk",
            "language:km",
            "language:ko",
            "language:ku",
            "language:kw",
            "language:la",
            "language:lb",
            "language:lt",
            "language:lv",
            "language:mi",
            "language:mk",
            "language:ml",
            "language:mn",
            "language:mr",
            "language:ms",
            "language:mt",
            "language:my",
            "language:nb",
            "language:nl",
            "language:nn",
            "language:no",
            "language:oc",
            "language:pl",
            "language:pt",
            "language:qu",
            "language:rn",
            "language:ro",
            "language:ru",
            "language:sh",
            "language:sl",
            "language:sq",
            "language:sr",
            "language:sv",
            "language:sw",
            "language:ta",
            "language:te",
            "language:th",
            "language:tk",
            "language:tl",
            "language:tr",
            "language:tt",
            "language:ug",
            "language:uk",
            "language:ur",
            "language:uz",
            "language:vi",
            "language:vo",
            "language:yi",
            "language:zh",
            "license:cc-by-2.0",
            "region:us"
        ],
        "createdAt": "2022-03-02T23:29:22.000Z",
        "key": ""
    },
    {
        "_id": "621ffdd236468d709f182025",
        "id": "cambridgeltl/xcopa",
        "author": "cambridgeltl",
        "disabled": false,
        "gated": false,
        "lastModified": "2024-01-04T16:55:46.000Z",
        "likes": 10,
        "private": false,
        "sha": "042f78955ba48e6404616762fa6e05e839c3907a",
        "description": "\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for \"xcopa\"\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\n  XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning\nThe Cross-lingual Choice of Plausible Alternatives dataset is a benchmark to evaluate the ability of machine learning models to transfer commonsense reasoning across\nlanguages. The dataset is the translation and reannotation of the English COPA (Roemmele et al. 2011) and covers 11 languages from 11 families and several areas around\nthe globe. The dataset is\u2026 See the full description on the dataset page: https://huggingface.co/datasets/cambridgeltl/xcopa.",
        "downloads": 14763,
        "paperswithcode_id": "xcopa",
        "tags": [
            "task_categories:question-answering",
            "task_ids:multiple-choice-qa",
            "annotations_creators:expert-generated",
            "language_creators:expert-generated",
            "multilinguality:multilingual",
            "source_datasets:extended|copa",
            "language:et",
            "language:ht",
            "language:id",
            "language:it",
            "language:qu",
            "language:sw",
            "language:ta",
            "language:th",
            "language:tr",
            "language:vi",
            "language:zh",
            "license:cc-by-4.0",
            "size_categories:10K<n<100K",
            "format:parquet",
            "modality:tabular",
            "modality:text",
            "library:datasets",
            "library:pandas",
            "library:mlcroissant",
            "region:us",
            "croissant"
        ],
        "createdAt": "2022-03-02T23:29:22.000Z",
        "key": ""
    },
    {
        "_id": "621ffdd236468d709f181f95",
        "id": "rajpurkar/squad",
        "author": "rajpurkar",
        "disabled": false,
        "gated": false,
        "lastModified": "2024-03-04T13:54:37.000Z",
        "likes": 227,
        "private": false,
        "sha": "7b6d24c440a36b6815f21b70d25016731768db1f",
        "description": "\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for SQuAD\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nStanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.\nSQuAD 1.1 contains 100,000+ question-answer pairs on 500+ articles.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nQuestion\u2026 See the full description on the dataset page: https://huggingface.co/datasets/rajpurkar/squad.",
        "downloads": 11971,
        "paperswithcode_id": "squad",
        "tags": [
            "task_categories:question-answering",
            "task_ids:extractive-qa",
            "annotations_creators:crowdsourced",
            "language_creators:crowdsourced",
            "language_creators:found",
            "multilinguality:monolingual",
            "source_datasets:extended|wikipedia",
            "language:en",
            "license:cc-by-sa-4.0",
            "size_categories:10K<n<100K",
            "format:parquet",
            "modality:text",
            "library:datasets",
            "library:pandas",
            "library:mlcroissant",
            "arxiv:1606.05250",
            "region:us",
            "croissant"
        ],
        "createdAt": "2022-03-02T23:29:22.000Z",
        "key": ""
    },
    {
        "_id": "621ffdd236468d709f182347",
        "id": "GEM/wiki_lingua",
        "author": "GEM",
        "disabled": false,
        "gated": false,
        "lastModified": "2023-02-16T09:23:29.000Z",
        "likes": 47,
        "private": false,
        "sha": "af5d0f00b59a6933165c97b384f50d8b563c314d",
        "citation": "@article{ladhak-wiki-2020,\n  title   = {WikiLingua: A New Benchmark Dataset for Multilingual Abstractive Summarization},\n  authors = {Faisal Ladhak, Esin Durmus, Claire Cardie and Kathleen McKeown},\n  journal = {arXiv preprint arXiv:2010.03093},\n  year    = {2020},\n  url     = {https://arxiv.org/abs/2010.03093}\n}",
        "description": "WikiLingua is a large-scale multilingual dataset for the evaluation of\ncrosslingual abstractive summarization systems. The dataset includes ~770k\narticle and summary pairs in 18 languages from WikiHow. The gold-standard\narticle-summary alignments across languages was done by aligning the images\nthat are used to describe each how-to step in an article.",
        "downloads": 11776,
        "tags": [
            "task_categories:summarization",
            "annotations_creators:none",
            "language_creators:unknown",
            "multilinguality:multilingual",
            "source_datasets:original",
            "language:ar",
            "language:cs",
            "language:de",
            "language:en",
            "language:es",
            "language:fr",
            "language:hi",
            "language:id",
            "language:it",
            "language:ja",
            "language:ko",
            "language:nl",
            "language:pt",
            "language:ru",
            "language:th",
            "language:tr",
            "language:vi",
            "language:zh",
            "license:cc-by-nc-sa-3.0",
            "size_categories:10M<n<100M",
            "modality:text",
            "library:datasets",
            "library:mlcroissant",
            "region:us",
            "croissant"
        ],
        "createdAt": "2022-03-02T23:29:22.000Z",
        "key": ""
    },
    {
        "_id": "621ffdd236468d709f18202d",
        "id": "EdinburghNLP/xsum",
        "author": "EdinburghNLP",
        "disabled": false,
        "gated": false,
        "lastModified": "2023-04-05T13:45:25.000Z",
        "likes": 71,
        "private": false,
        "sha": "40db7604fedb616a9d2b0673d11838fa5be8451c",
        "citation": "@article{Narayan2018DontGM,\n  title={Don't Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization},\n  author={Shashi Narayan and Shay B. Cohen and Mirella Lapata},\n  journal={ArXiv},\n  year={2018},\n  volume={abs/1808.08745}\n}",
        "description": "Extreme Summarization (XSum) Dataset.\n\nThere are three features:\n  - document: Input news article.\n  - summary: One sentence summary of the article.\n  - id: BBC ID of the article.",
        "downloads": 11378,
        "paperswithcode_id": "xsum",
        "tags": [
            "task_categories:summarization",
            "task_ids:news-articles-summarization",
            "annotations_creators:found",
            "language_creators:found",
            "multilinguality:monolingual",
            "source_datasets:original",
            "language:en",
            "license:unknown",
            "size_categories:100K<n<1M",
            "modality:text",
            "library:datasets",
            "library:mlcroissant",
            "arxiv:1808.08745",
            "region:us",
            "croissant"
        ],
        "createdAt": "2022-03-02T23:29:22.000Z",
        "key": ""
    },
    {
        "_id": "621ffdd236468d709f182012",
        "id": "allenai/winogrande",
        "author": "allenai",
        "disabled": false,
        "gated": false,
        "lastModified": "2024-01-18T11:18:22.000Z",
        "likes": 50,
        "private": false,
        "sha": "85ac5b5a3b7a930e22d590176e39460400d19e41",
        "citation": "@InProceedings{ai2:winogrande,\ntitle = {WinoGrande: An Adversarial Winograd Schema Challenge at Scale},\nauthors={Keisuke, Sakaguchi and Ronan, Le Bras and Chandra, Bhagavatula and Yejin, Choi\n},\nyear={2019}\n}",
        "description": "WinoGrande is a new collection of 44k problems, inspired by Winograd Schema Challenge (Levesque, Davis, and Morgenstern\n 2011), but adjusted to improve the scale and robustness against the dataset-specific bias. Formulated as a\nfill-in-a-blank task with binary options, the goal is to choose the right option for a given sentence which requires\ncommonsense reasoning.",
        "downloads": 10835,
        "paperswithcode_id": "winogrande",
        "tags": [
            "language:en",
            "region:us"
        ],
        "createdAt": "2022-03-02T23:29:22.000Z",
        "key": ""
    },
    {
        "_id": "621ffdd236468d709f181f54",
        "id": "webis/tldr-17",
        "author": "webis",
        "disabled": false,
        "gated": false,
        "lastModified": "2023-06-05T12:48:30.000Z",
        "likes": 36,
        "private": false,
        "sha": "fa7f50e62d35aff41aa165ddbe6c10dfa01ff49c",
        "citation": "@inproceedings{volske-etal-2017-tl,\n    title = {TL;DR: Mining {R}eddit to Learn Automatic Summarization},\n    author = {V{\\\"o}lske, Michael  and Potthast, Martin  and Syed, Shahbaz  and Stein, Benno},\n    booktitle = {Proceedings of the Workshop on New Frontiers in Summarization},\n    month = {sep},\n    year = {2017},\n    address = {Copenhagen, Denmark},\n    publisher = {Association for Computational Linguistics},\n    url = {https://www.aclweb.org/anthology/W17-4508},\n    doi = {10.18653/v1/W17-4508},\n    pages = {59--63},\n    abstract = {Recent advances in automatic text summarization have used deep neural networks to generate high-quality abstractive summaries, but the performance of these models strongly depends on large amounts of suitable training data. We propose a new method for mining social media for author-provided summaries, taking advantage of the common practice of appending a {``}TL;DR{''} to long posts. A case study using a large Reddit crawl yields the Webis-TLDR-17 dataset, complementing existing corpora primarily from the news genre. Our technique is likely applicable to other social media sites and general web crawls.},\n}",
        "description": "This corpus contains preprocessed posts from the Reddit dataset.\nThe dataset consists of 3,848,330 posts with an average length of 270 words for content,\nand 28 words for the summary.\n\nFeatures includes strings: author, body, normalizedBody, content, summary, subreddit, subreddit_id.\nContent is used as document and summary is used as summary.",
        "downloads": 10742,
        "paperswithcode_id": "webis-tldr-17-corpus",
        "tags": [
            "task_categories:summarization",
            "annotations_creators:no-annotation",
            "language_creators:crowdsourced",
            "multilinguality:monolingual",
            "source_datasets:original",
            "language:en",
            "license:cc-by-4.0",
            "size_categories:1M<n<10M",
            "modality:text",
            "library:datasets",
            "library:mlcroissant",
            "region:us",
            "reddit-posts-summarization",
            "croissant"
        ],
        "createdAt": "2022-03-02T23:29:22.000Z",
        "key": ""
    },
    {
        "_id": "621ffdd236468d709f181f62",
        "id": "Samsung/samsum",
        "author": "Samsung",
        "disabled": false,
        "gated": false,
        "lastModified": "2024-01-18T11:15:13.000Z",
        "likes": 281,
        "private": false,
        "sha": "f00baf5a7d4abfec6820415493bcb52c587788e6",
        "citation": "@article{gliwa2019samsum,\n  title={SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization},\n  author={Gliwa, Bogdan and Mochol, Iwona and Biesek, Maciej and Wawer, Aleksander},\n  journal={arXiv preprint arXiv:1911.12237},\n  year={2019}\n}",
        "description": "SAMSum Corpus contains over 16k chat dialogues with manually annotated\nsummaries.\nThere are two features:\n  - dialogue: text of dialogue.\n  - summary: human written summary of the dialogue.\n  - id: id of a example.",
        "downloads": 9985,
        "paperswithcode_id": "samsum-corpus",
        "tags": [
            "task_categories:summarization",
            "annotations_creators:expert-generated",
            "language_creators:expert-generated",
            "multilinguality:monolingual",
            "source_datasets:original",
            "language:en",
            "license:cc-by-nc-nd-4.0",
            "size_categories:10K<n<100K",
            "arxiv:1911.12237",
            "region:us",
            "conversations-summarization"
        ],
        "createdAt": "2022-03-02T23:29:22.000Z",
        "key": ""
    },
    {
        "_id": "621ffdd236468d709f18200d",
        "id": "Salesforce/wikitext",
        "author": "Salesforce",
        "disabled": false,
        "gated": false,
        "lastModified": "2024-01-04T16:49:18.000Z",
        "likes": 311,
        "private": false,
        "sha": "b08601e04326c79dfdd32d625aee71d232d685c3",
        "description": "\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for \"wikitext\"\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\n The WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified\n Good and Featured articles on Wikipedia. The dataset is available under the Creative Commons Attribution-ShareAlike License.\nCompared to the preprocessed version of Penn Treebank (PTB), WikiText-2 is over 2 times larger and WikiText-103 is over\n110 times larger. The WikiText dataset also features a far\u2026 See the full description on the dataset page: https://huggingface.co/datasets/Salesforce/wikitext.",
        "downloads": 9926,
        "paperswithcode_id": "wikitext-2",
        "tags": [
            "task_categories:text-generation",
            "task_categories:fill-mask",
            "task_ids:language-modeling",
            "task_ids:masked-language-modeling",
            "annotations_creators:no-annotation",
            "language_creators:crowdsourced",
            "multilinguality:monolingual",
            "source_datasets:original",
            "language:en",
            "license:cc-by-sa-3.0",
            "license:gfdl",
            "size_categories:1M<n<10M",
            "format:parquet",
            "modality:text",
            "library:datasets",
            "library:dask",
            "library:mlcroissant",
            "arxiv:1609.07843",
            "region:us",
            "croissant"
        ],
        "createdAt": "2022-03-02T23:29:22.000Z",
        "key": ""
    },
    {
        "_id": "621ffdd236468d709f181dba",
        "id": "abisee/cnn_dailymail",
        "author": "abisee",
        "disabled": false,
        "gated": false,
        "lastModified": "2024-01-18T15:31:34.000Z",
        "likes": 189,
        "private": false,
        "sha": "96df5e686bee6baa90b8bee7c28b81fa3fa6223d",
        "description": "\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for CNN Dailymail Dataset\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe CNN / DailyMail Dataset is an English-language dataset containing just over 300k unique news articles as written by journalists at CNN and the Daily Mail. The current version supports both extractive and abstractive summarization, though the original version was created for machine reading and comprehension and abstractive question answering. \n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks and Leaderboards\u2026 See the full description on the dataset page: https://huggingface.co/datasets/abisee/cnn_dailymail.",
        "downloads": 9258,
        "paperswithcode_id": "cnn-daily-mail-1",
        "tags": [
            "task_categories:summarization",
            "task_ids:news-articles-summarization",
            "annotations_creators:no-annotation",
            "language_creators:found",
            "multilinguality:monolingual",
            "source_datasets:original",
            "language:en",
            "license:apache-2.0",
            "size_categories:100K<n<1M",
            "format:parquet",
            "modality:text",
            "library:datasets",
            "library:dask",
            "library:mlcroissant",
            "region:us",
            "croissant"
        ],
        "createdAt": "2022-03-02T23:29:22.000Z",
        "key": ""
    }
]